{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M21CS056_M21CS017_M21CS014.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxr1hPUs-Ifi"
      },
      "source": [
        "# Here we using the libraries which are required to carry out different tasks\n",
        "\n",
        "import seaborn as sns\n",
        "from keras.utils.np_utils import to_categorical as zeroone\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "from random import choice\n",
        "from keras.layers import Conv2D, Dense, GlobalAveragePooling2D, Flatten\n",
        "from keras import models\n",
        "from random import uniform\n",
        "from keras import layers\n",
        "import tensorflow as tf"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F6BfJgE-RNo"
      },
      "source": [
        "# Here we are loading mnist dataset from keras dataset\n",
        " \n",
        "# It returns the values in pairs, so getting those as (X_train, y_train) as one pair and (X_test, y_test) as other pair\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19f6F4Wr-XaQ",
        "outputId": "dd2aa361-5f2d-449c-b873-1f20463a582d"
      },
      "source": [
        "# Printing the shape of X_train & y_train\n",
        "# This indicates we have 60000 images each with 28 rows & 28 columns\n",
        "print(X_train.shape)\n",
        "\n",
        "# This indicates we have 10000 images\n",
        "y_train.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnSFUagI-b4g",
        "outputId": "f9dc2019-3fa1-4a9a-8cd6-43c75f2b03e9"
      },
      "source": [
        "# Printing the shape of X_test & y_test\n",
        "# This indicates we have 10000 images each with 28 rows & 28 columns\n",
        "print(X_test.shape)\n",
        "\n",
        "# This indicates we have 10000 images\n",
        "y_test.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JJTt9yN-nCZ",
        "outputId": "8db61133-4394-4465-cca7-1d3854ab7b37"
      },
      "source": [
        "# Printing value of X_train\n",
        "# Each 2D array contains 28*28 pixels of 1 image\n",
        "X_train"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5YPY5JxJypL",
        "outputId": "d531f13f-f926-49e2-adf8-561e26ab1cc5"
      },
      "source": [
        "# Printing value of y_train\n",
        "# This basically contains the number of output classes we have\n",
        "y_train"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "z23EQTKV_Jmi",
        "outputId": "49cfd5eb-7caf-408c-c6ff-3f03bb5ec32f"
      },
      "source": [
        "# Seeing what exactly present in that particular index of y_train, i.e, displaying the image itself\n",
        " \n",
        "plt.imshow(X_train[7])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd3ac24bb10>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "BWGjsPIu_SnY",
        "outputId": "aabc4d72-2475-4c6d-ba79-3d10676fc7b0"
      },
      "source": [
        "# Showing image in grey colour\n",
        "plt.imshow(X_train[9], cmap='Greys')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd3ac1ade90>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iuVQGfCQEfM"
      },
      "source": [
        "# Changing our dataset from 3D to 4D, because CNN requires 4D data\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4KCcE5rQGzN"
      },
      "source": [
        "# Doing feature scaling here, so that values lies between 0 and 1 only\n",
        "train_images =X_train.astype('float32')/255\n",
        "test_images=X_test.astype('float32')/255"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9AWW_WkkuW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf5f320-5736-4a15-83cc-b12572612ab0"
      },
      "source": [
        "# Converting all y_train and y_test datas into a boolean matrix of 0's and 1's\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "train_labels=zeroone(y_train)\n",
        "# Here no of rows = length of the input & no of cols = number of classes (here in our case 0-9)\n",
        "test_labels=zeroone(y_test)\n",
        "test_labels"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 0 0 ... 3 0 5]\n",
            "[9 2 1 ... 8 1 5]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vib6wTPgkxt4"
      },
      "source": [
        "# Splitting data into training and validation part\n",
        "\n",
        "validation_img=train_images[:10000]\n",
        "img=train_images[10000:]\n",
        "\n",
        "validation_lbl=train_labels[:10000]\n",
        "lbl=train_labels[10000:]"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBEA0PpQQlLA"
      },
      "source": [
        "# Here we make our model by randomly assigning values to various parameters\n",
        "\n",
        "def making_model( normalcnnlayerfilter, reductioncnnlayer1filter, reductioncnnlayer2filter, normallayerkernel, reductionlayerkernel, nrmllyractfn, rdclyractfn, epochs):\n",
        "\n",
        "    making_model=models.Sequential()    \n",
        "    \n",
        "    #Normal CNN Layer with Stride=1, Padding=SAME, 1<=kernel<8, and any of one activation function\n",
        "    making_model.add(layers.Conv2D(filters=normalcnnlayerfilter, kernel_size=(2,2), activation=nrmllyractfn, strides=(1,1), padding='SAME', input_shape=[28,28,1]))\n",
        "    \n",
        "    #Reduction CNN Layer 1 with Stride=2, Padding=VALID, 1<=kernel<8, and any of one activation function\n",
        "    making_model.add(layers.Conv2D(filters=reductioncnnlayer1filter, kernel_size=(2,2), activation=rdclyractfn, strides=(2,2), padding='valid'))\n",
        "    \n",
        "    #Reduction CNN Layer 2 with Stride=2, Padding=VALID, 1<=kernel<8, and any of one activation function\n",
        "    making_model.add(layers.Conv2D(filters=reductioncnnlayer1filter, kernel_size=(2,2), activation=rdclyractfn, strides=(2,2), padding='valid'))\n",
        "    \n",
        "    #Final CNN layer with Globel Average Pooling\n",
        "    making_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    #Flatten our data\n",
        "    making_model.add(layers.Flatten())\n",
        "\n",
        "    # In order to avoid overfitting, using dropout\n",
        "    #making_model.add(layers.Dropout(rate = frstdrpt))\n",
        "\n",
        "    #Fully connected dense layer with 64 units & an activation function\n",
        "    making_model.add(layers.Dense(units = 64, activation = \"sigmoid\"))\n",
        "\n",
        "    \n",
        "    # Output with 10 layers ranging from 0 to 9, each indicating the type of cloth\n",
        "    making_model.add(layers.Dense(10, activation= \"sigmoid\"))\n",
        "\n",
        "    # Compiling our cnn model which we make above with layers\n",
        "    making_model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy']) # metrics to find accuracy\n",
        "    \n",
        "    #Fitting our model\n",
        "    making_model.fit(img, lbl, validation_data=(validation_img,validation_lbl), epochs=epochs, batch_size = 100, verbose=1)\n",
        "\n",
        "    \n",
        "    #Returning our model \n",
        "    return making_model\n",
        " \n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBgLRG9naN9f"
      },
      "source": [
        "# This code will take random values of the parameter which will get assign to our CNN model\n",
        "\n",
        "def assign_random_values_to_parameters():\n",
        "  \n",
        "  # This indicates the number of paramater in our cnn model\n",
        "  cnn_model_parameters = {}\n",
        "\n",
        "  # This will choose normal CNN Layer Filters\n",
        "  normalcnnlayerfilter = choice([32, 128, 8, 256,16, 64])\n",
        "  cnn_model_parameters[\"normalcnnlayerfilter\"] = normalcnnlayerfilter\n",
        "  \n",
        "  # This will choose Reduction CNN Layer 1 Filters\n",
        "  get = choice([256, 128, 8, 32,16, 64])\n",
        "  reductioncnnlayer1filter=get\n",
        "  cnn_model_parameters[\"reductioncnnlayer1filter\"] = reductioncnnlayer1filter\n",
        "  \n",
        "  # This will choose Reduction CNN Layer 2 Filters\n",
        "  reductioncnnlayer2filter = get\n",
        "  cnn_model_parameters[\"reductioncnnlayer2filter\"] = reductioncnnlayer2filter\n",
        "  \n",
        "  # This will choose Normal CNN Layer Kernal matrix\n",
        "  normallayerkernel = choice([1,2,3,4,5,6,7])\n",
        "  cnn_model_parameters[\"normallayerkernel\"] =normallayerkernel\n",
        "  \n",
        "  # This will choose Reduction CNN Layer Kernal matrix\n",
        "  reductionlayerkernel = choice([1,2,3,4,5,6,7])\n",
        "  cnn_model_parameters[\"reductionlayerkernel\"] = reductionlayerkernel\n",
        "  \n",
        "  # This will choose Normal CNN Layer Activation Function\n",
        "  nrmllyractfn = choice([\"relu\", \"sigmoid\", \"tanh\",\"swish\",\"gelu\"])\n",
        "  cnn_model_parameters[\"nrmllyractfn\"] = nrmllyractfn\n",
        "  \n",
        "  # This will choose Reduction CNN Layer Activation Function\n",
        "  # For both of our Reduction CNN layers, the activation function, number of filters, kernel matrix size, all are same\n",
        "  rdclyractfn = choice([\"relu\", \"sigmoid\", \"tanh\",\"swish\",\"gelu\"])\n",
        "  cnn_model_parameters[\"rdclyractfn\"] = rdclyractfn\n",
        "  \n",
        "  # Optimizer is same\n",
        "  optmzr = \"adam\"\n",
        "  cnn_model_parameters[\"optmzr\"] = optmzr\n",
        "  \n",
        "  #epochs can be any integer between 10 and 30\n",
        "  epochs = randint(10, 30)\n",
        "  cnn_model_parameters[\"epochs\"] = epochs\n",
        "  \n",
        "  return cnn_model_parameters"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmKLi2SfeeHr"
      },
      "source": [
        "# Genetic Algorithm Step 1, making initial population so that we can able to start the reproduction phase\n",
        "\n",
        "#Passed initial number of peoples in population\n",
        "def making_initial_population(number_of_people_in_population):\n",
        "  peoples_with_parameters = []\n",
        "  for i in range(number_of_people_in_population):\n",
        "    # For each person assigning it with random values of parameters\n",
        "    cnn_model_parameters = assign_random_values_to_parameters()\n",
        "    #Appending those values to peoples\n",
        "    peoples_with_parameters.append(cnn_model_parameters)\n",
        "  return peoples_with_parameters"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2OuBHc3fLqm"
      },
      "source": [
        "# Step 2.1: Finding out the fitness values of each of the individual people in our population \n",
        "def compute_fitness(cnnmdl):\n",
        "  # This will evaluate the accuracy of our model\n",
        "  res = cnnmdl.evaluate(test_images, test_labels)\n",
        "  \n",
        "  #returning 1st index value of res, because it contains value of accuracy, and 0th index contains value of loss\n",
        "  return res[1]"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2abAPm2hL9J"
      },
      "source": [
        "# Step 2.2: Selecting the best individual out of all the individuals from our population by using Roulette wheel selection method\n",
        "def rltwhlslct(fitness_of_population):\n",
        "  #Finding out the total fitness score of our whole population\n",
        "  total = sum(fitness_of_population)\n",
        "  \n",
        "  #Finding out the weightage of fitness score of each of individual in our population\n",
        "  weightage = [round((x/total) * 100) for x in fitness_of_population]\n",
        "  \n",
        "  #This is the wheel which we rotate, and then on the basis where the pointer points in the wheel, that individual will be choosen\n",
        "  roulette_pointer_wheel = []\n",
        "\n",
        "  #Here enumerting the weightage array, so that we get values in the form of key->value pairs with key starting from 0\n",
        "  for sample_space_ind,value in enumerate(weightage):\n",
        "    \n",
        "    #Here we are appending the output in our roulette_pointer_wheel array\n",
        "    roulette_pointer_wheel.extend([sample_space_ind]*value)\n",
        "\n",
        "  #Sorting the weights\n",
        "  roulette_pointer_wheel.sort()\n",
        "  # Taking the maximum as our 1st parent\n",
        "  parent1 = roulette_pointer_wheel[-1]\n",
        "  # Taking the second maximum as our 2nd parent\n",
        "  parent2 = roulette_pointer_wheel[-2]\n",
        "  #Returning those 2 parents\n",
        "  return [parent1, parent2]"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsfeRsaSfNUK"
      },
      "source": [
        "#Step 3: Doing Cross-over of the 2 fittest individual from our model\n",
        "\n",
        "# Here we passed both the parents along with there parameter values\n",
        "def parent_cross_over(first_parent, second_parent):\n",
        "  \n",
        "  # From this function we expect 2 childrens to return\n",
        "  first_child = {}\n",
        "  # Making dictionary of both the children\n",
        "  second_child = {}\n",
        "\n",
        "  # First child's normalcnnlayerfilter can be any of 1st parent's or 2nd parent's normalcnnlayerfilter\n",
        "  first_child[\"normalcnnlayerfilter\"] = choice([first_parent[\"normalcnnlayerfilter\"], second_parent[\"normalcnnlayerfilter\"]])\n",
        "  \n",
        "  # First child's reductioncnnlayer1filter can be any of 1st parent's or 2nd parent's reductioncnnlayer1filter\n",
        "  first_child[\"reductioncnnlayer1filter\"] = choice([first_parent[\"reductioncnnlayer1filter\"], second_parent[\"reductioncnnlayer1filter\"]])\n",
        "  \n",
        "  # First child's reductioncnnlayer2filter can be any of 1st parent's or 2nd parent's reductioncnnlayer2filter\n",
        "  first_child[\"reductioncnnlayer2filter\"] = choice([first_parent[\"reductioncnnlayer2filter\"], second_parent[\"reductioncnnlayer2filter\"]])\n",
        "\n",
        "  # Second child's reductioncnnlayer1filter can be any of 1st parent's or 2nd parent's reductioncnnlayer1filter\n",
        "  second_child[\"normalcnnlayerfilter\"] = choice([first_parent[\"normalcnnlayerfilter\"], second_parent[\"normalcnnlayerfilter\"]])\n",
        "  \n",
        "  # Second child's reductioncnnlayer2filter can be any of 1st parent's or 2nd parent's reductioncnnlayer2filter\n",
        "  second_child[\"reductioncnnlayer1filter\"] = choice([first_parent[\"reductioncnnlayer1filter\"], second_parent[\"reductioncnnlayer1filter\"]])\n",
        "  second_child[\"reductioncnnlayer2filter\"] = choice([first_parent[\"reductioncnnlayer2filter\"], second_parent[\"reductioncnnlayer2filter\"]])\n",
        "\n",
        "  # First child's normalkernellayer can be any of 1st parent's or 2nd parent's normalkernellayer\n",
        "  first_child[\"normallayerkernel\"] = choice([first_parent[\"normallayerkernel\"], second_parent[\"normallayerkernel\"]])\n",
        "  \n",
        "  # Second child's normalkernellayer can be any of 1st parent's or 2nd parent's normalkernellayer\n",
        "  second_child[\"normallayerkernel\"] = choice([first_parent[\"normallayerkernel\"], second_parent[\"normallayerkernel\"]])\n",
        "  \n",
        "  # First child's reductionkernellayer can be any of 1st parent's or 2nd parent's reductionkernellayer\n",
        "  first_child[\"reductionlayerkernel\"] = choice([first_parent[\"reductionlayerkernel\"], second_parent[\"reductionlayerkernel\"]])\n",
        "  \n",
        "  # Second child's reductionkernellayer can be any of 1st parent's or 2nd parent's reductionkernellayer\n",
        "  second_child[\"reductionlayerkernel\"] = choice([first_parent[\"reductionlayerkernel\"], second_parent[\"reductionlayerkernel\"]])\n",
        "\n",
        "  # Here Doing the Crossover of parent features in child, so as to get best results\n",
        "  # First child's normal activation function is 1st parent's reduction activation function\n",
        "  first_child[\"nrmllyractfn\"] = first_parent[\"rdclyractfn\"]\n",
        "  \n",
        "  # Second child's normal activation function is 2nd parent's reduction activation function\n",
        "  second_child[\"nrmllyractfn\"] = second_parent[\"rdclyractfn\"]\n",
        "\n",
        "  # First child's reduction activation function is 1st parent's normal activation function\n",
        "  first_child[\"rdclyractfn\"] = second_parent[\"nrmllyractfn\"]\n",
        "  \n",
        "  # Second child's reduction activation function is 1st parent's normal activation function\n",
        "  second_child[\"rdclyractfn\"] = first_parent[\"nrmllyractfn\"]\n",
        "\n",
        "  # Again cross-oover here so to get diverse characteristics\n",
        "  # First child's optimizer is 2nd parent's optimizer\n",
        "  first_child[\"optmzr\"] = second_parent[\"optmzr\"]\n",
        "\n",
        "  # Second child's optimizer is 1st parent's optimizer\n",
        "  second_child[\"optmzr\"] = first_parent[\"optmzr\"]\n",
        "\n",
        "  # First child's epochs is 1st parent's epochs\n",
        "  first_child[\"epochs\"] = first_parent[\"epochs\"]\n",
        "\n",
        "  # Second child's epochs is 2nd parent's epochs\n",
        "  second_child[\"epochs\"] = second_parent[\"epochs\"]\n",
        "  \n",
        "  # Returing both the offsprings which we get here by doing cross-over of the 2 parents above\n",
        "  return [first_child, second_child]"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsT-QwaGhFma"
      },
      "source": [
        "# Step 4: In this we mutating the child so as to get the diverse characteristics in the child\n",
        "def child_mutn(individual):\n",
        "  answr = randint(0,50)\n",
        "  if answr <= 30:\n",
        "    # Randomly inreasing the number of epochs so as to make it more\n",
        "    individual[\"epochs\"] += randint(0, 20)\n",
        "  return individual"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4gBJeNehHoP",
        "outputId": "eadb614b-d408-4238-b9f5-22bba3de2eca"
      },
      "source": [
        "#Making our model to run for the given number of generations & giving the size of initial population\n",
        "\n",
        "# Indicates the total number of generations\n",
        "number_of_generations = 3\n",
        "\n",
        "#Indicates the number of peoples in our population\n",
        "number_of_people_in_population = 4\n",
        "\n",
        "# Making a dictionary which contains key->value pairs which contains key as the accuracy & value as the paramters of our cnn model which gets that accuracy\n",
        "track_of_param_and_accuracy={}\n",
        "\n",
        "# This indicates the maximum accuracy value along with its parameters\n",
        "highest_acc_with_param=0\n",
        "\n",
        "#Making our population with the given number of individuals and here we get all peoples with parameters\n",
        "peoples = making_initial_population(number_of_people_in_population)\n",
        "\n",
        "# Here we are iterating each of generation so as to get result in each generation\n",
        "for each_gen in range(number_of_generations):\n",
        "  print(\"Currently Runnung Generation is:\",each_gen+1)\n",
        "\n",
        "  # This contains the list of all the accuracies we got\n",
        "  list_of_accuracies = []\n",
        "  # Iterating for each of our individual person in the population\n",
        "  for individual in peoples:\n",
        "    #Taking values of each parameter from the peoples array\n",
        "    \n",
        "    # Taking value of normal filter\n",
        "    normalcnnlayerfilter = individual[\"normalcnnlayerfilter\"]\n",
        "    \n",
        "    # Taking value of reduction layer 1 filter\n",
        "    reductioncnnlayer1filter = individual[\"reductioncnnlayer1filter\"]\n",
        "    \n",
        "    # Taking value of reduction layer 2 filter\n",
        "    reductioncnnlayer2filter = individual[\"reductioncnnlayer2filter\"]\n",
        "    \n",
        "    # Taking value of normal layer kernel\n",
        "    normallayerkernel = individual[\"normallayerkernel\"]\n",
        "    \n",
        "     # Taking value of reduction layer kernel\n",
        "    reductionlayerkernel = individual[\"reductionlayerkernel\"]\n",
        "    \n",
        "     # Taking value of normal activation function\n",
        "    nrmllyractfn = individual[\"nrmllyractfn\"]\n",
        "    \n",
        "    # Taking value of redcution activation function\n",
        "    rdclyractfn = individual[\"rdclyractfn\"]\n",
        "    #frstdrpt = individual[\"frstdrpt\"]\n",
        "    #scnddrpt = individual[\"scnddrpt\"]\n",
        "    \n",
        "    # Taking value of optimizer\n",
        "    optmzr = individual[\"optmzr\"]\n",
        "\n",
        "    # Taking value of epochs\n",
        "    epochs = individual[\"epochs\"]\n",
        "    \n",
        "    #With those values making our model\n",
        "    cnn_model_making = making_model(normalcnnlayerfilter, reductioncnnlayer1filter, reductioncnnlayer2filter, normallayerkernel, reductionlayerkernel, nrmllyractfn, rdclyractfn, epochs)\n",
        "    # Finding out the fitness of our model\n",
        "    gotten_accuracy = compute_fitness(cnn_model_making)\n",
        "    print(\"The parameters of CNN Model are: \", individual)\n",
        "    print(\"The accuracy of CNN Model is: \", round(gotten_accuracy,3))\n",
        "\n",
        "    # This will contain like key->value pair, which tells the accuracy and its corresponding parameters\n",
        "    track_of_param_and_accuracy[gotten_accuracy]= individual\n",
        "    \n",
        "    #This will pull out that one who has maximum accuracy\n",
        "    highest_acc_with_param=max(track_of_param_and_accuracy)\n",
        "    \n",
        "    #Appending that accuracy in our list\n",
        "    list_of_accuracies.append(gotten_accuracy)\n",
        "\n",
        "  #Sending the list of all accuracies in roulette_pointer_wheel function & returning the fittest 2 parents\n",
        "  two_fittest_persons = rltwhlslct(list_of_accuracies)\n",
        "  parent1 = peoples[two_fittest_persons[0]]\n",
        "  parent2 = peoples[two_fittest_persons[1]]\n",
        "\n",
        "  # Sending those 2 parents with parameters to cross-over function so as to produce an offspring\n",
        "  childs = parent_cross_over(parent1, parent2)\n",
        "  \n",
        "  #Doing the mutation of each of the child, so as to get the diverse characteristics in the child\n",
        "  child1 = child_mutn(childs[0])\n",
        "  child2 = child_mutn(childs[1])\n",
        "\n",
        "  #Now appending those childs in our population, as they will lead the new generation\n",
        "  peoples.append(child1)\n",
        "  peoples.append(child2)\n",
        "\n",
        "  #Removing those who have least 2 accuracies\n",
        "  #Getting the 1st least one\n",
        "  least1 = min(list_of_accuracies)\n",
        "  #Getting index of 1st least\n",
        "  least1_index = list_of_accuracies.index(least1)\n",
        "  #Removing the 1st least\n",
        "  peoples.remove(peoples[least1_index])\n",
        "  #Getting the 2nd least one\n",
        "  least2 = min(list_of_accuracies)\n",
        "  #Getting index of 2nd least\n",
        "  least2_index = list_of_accuracies.index(least2)\n",
        "  #Removing the 2nd least\n",
        "  peoples.remove(peoples[least2_index])\n",
        "\n",
        "#print(track_of_param_and_accuracy.get(max_key))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently Runnung Generation is: 1\n",
            "Epoch 1/22\n",
            "500/500 [==============================] - 9s 16ms/step - loss: 1.8121 - accuracy: 0.3308 - val_loss: 1.2659 - val_accuracy: 0.5491\n",
            "Epoch 2/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 1.0853 - accuracy: 0.6190 - val_loss: 0.9467 - val_accuracy: 0.6644\n",
            "Epoch 3/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.9052 - accuracy: 0.6743 - val_loss: 0.8457 - val_accuracy: 0.6961\n",
            "Epoch 4/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.8257 - accuracy: 0.6998 - val_loss: 0.7973 - val_accuracy: 0.7064\n",
            "Epoch 5/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.7681 - accuracy: 0.7197 - val_loss: 0.7461 - val_accuracy: 0.7314\n",
            "Epoch 6/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.7273 - accuracy: 0.7367 - val_loss: 0.7209 - val_accuracy: 0.7327\n",
            "Epoch 7/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.6947 - accuracy: 0.7483 - val_loss: 0.6786 - val_accuracy: 0.7544\n",
            "Epoch 8/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.6637 - accuracy: 0.7595 - val_loss: 0.6455 - val_accuracy: 0.7687\n",
            "Epoch 9/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.6407 - accuracy: 0.7678 - val_loss: 0.6238 - val_accuracy: 0.7758\n",
            "Epoch 10/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.6186 - accuracy: 0.7767 - val_loss: 0.6015 - val_accuracy: 0.7835\n",
            "Epoch 11/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.6005 - accuracy: 0.7827 - val_loss: 0.6030 - val_accuracy: 0.7808\n",
            "Epoch 12/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5828 - accuracy: 0.7894 - val_loss: 0.5684 - val_accuracy: 0.7976\n",
            "Epoch 13/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.5626 - accuracy: 0.7976 - val_loss: 0.5625 - val_accuracy: 0.7943\n",
            "Epoch 14/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.5489 - accuracy: 0.8009 - val_loss: 0.5668 - val_accuracy: 0.7966\n",
            "Epoch 15/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.5358 - accuracy: 0.8049 - val_loss: 0.5333 - val_accuracy: 0.8078\n",
            "Epoch 16/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5210 - accuracy: 0.8114 - val_loss: 0.5093 - val_accuracy: 0.8160\n",
            "Epoch 17/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.5082 - accuracy: 0.8166 - val_loss: 0.5102 - val_accuracy: 0.8209\n",
            "Epoch 18/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.4991 - accuracy: 0.8189 - val_loss: 0.4845 - val_accuracy: 0.8262\n",
            "Epoch 19/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.4916 - accuracy: 0.8213 - val_loss: 0.4964 - val_accuracy: 0.8259\n",
            "Epoch 20/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.4777 - accuracy: 0.8287 - val_loss: 0.4807 - val_accuracy: 0.8294\n",
            "Epoch 21/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.4701 - accuracy: 0.8297 - val_loss: 0.4802 - val_accuracy: 0.8269\n",
            "Epoch 22/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.4603 - accuracy: 0.8356 - val_loss: 0.4654 - val_accuracy: 0.8337\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4859 - accuracy: 0.8281\n",
            "The parameters of CNN Model are:  {'normalcnnlayerfilter': 64, 'reductioncnnlayer1filter': 64, 'reductioncnnlayer2filter': 64, 'normallayerkernel': 7, 'reductionlayerkernel': 6, 'nrmllyractfn': 'swish', 'rdclyractfn': 'relu', 'optmzr': 'adam', 'epochs': 22}\n",
            "The accuracy of CNN Model is:  0.828\n",
            "Epoch 1/21\n",
            "500/500 [==============================] - 18s 34ms/step - loss: 1.9183 - accuracy: 0.2600 - val_loss: 1.6988 - val_accuracy: 0.3268\n",
            "Epoch 2/21\n",
            "500/500 [==============================] - 16s 32ms/step - loss: 1.5139 - accuracy: 0.4365 - val_loss: 1.3410 - val_accuracy: 0.4856\n",
            "Epoch 3/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 1.2411 - accuracy: 0.5365 - val_loss: 1.1692 - val_accuracy: 0.5761\n",
            "Epoch 4/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 1.1099 - accuracy: 0.5897 - val_loss: 1.0547 - val_accuracy: 0.6158\n",
            "Epoch 5/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 1.0180 - accuracy: 0.6272 - val_loss: 0.9808 - val_accuracy: 0.6511\n",
            "Epoch 6/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.9579 - accuracy: 0.6493 - val_loss: 0.9414 - val_accuracy: 0.6538\n",
            "Epoch 7/21\n",
            "500/500 [==============================] - 16s 32ms/step - loss: 0.9147 - accuracy: 0.6635 - val_loss: 0.9028 - val_accuracy: 0.6667\n",
            "Epoch 8/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.8847 - accuracy: 0.6742 - val_loss: 0.8733 - val_accuracy: 0.6809\n",
            "Epoch 9/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.8568 - accuracy: 0.6834 - val_loss: 0.8597 - val_accuracy: 0.6877\n",
            "Epoch 10/21\n",
            "500/500 [==============================] - 16s 32ms/step - loss: 0.8318 - accuracy: 0.6932 - val_loss: 0.8228 - val_accuracy: 0.7020\n",
            "Epoch 11/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.8174 - accuracy: 0.6995 - val_loss: 0.8133 - val_accuracy: 0.7041\n",
            "Epoch 12/21\n",
            "500/500 [==============================] - 16s 32ms/step - loss: 0.7964 - accuracy: 0.7071 - val_loss: 0.7900 - val_accuracy: 0.7116\n",
            "Epoch 13/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.7752 - accuracy: 0.7164 - val_loss: 0.7763 - val_accuracy: 0.7148\n",
            "Epoch 14/21\n",
            "500/500 [==============================] - 16s 32ms/step - loss: 0.7577 - accuracy: 0.7223 - val_loss: 0.7417 - val_accuracy: 0.7313\n",
            "Epoch 15/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.7420 - accuracy: 0.7312 - val_loss: 0.7288 - val_accuracy: 0.7390\n",
            "Epoch 16/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.7254 - accuracy: 0.7373 - val_loss: 0.7113 - val_accuracy: 0.7485\n",
            "Epoch 17/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.7133 - accuracy: 0.7434 - val_loss: 0.7100 - val_accuracy: 0.7527\n",
            "Epoch 18/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.6956 - accuracy: 0.7491 - val_loss: 0.6826 - val_accuracy: 0.7600\n",
            "Epoch 19/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.6795 - accuracy: 0.7548 - val_loss: 0.6797 - val_accuracy: 0.7618\n",
            "Epoch 20/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.6635 - accuracy: 0.7622 - val_loss: 0.6619 - val_accuracy: 0.7712\n",
            "Epoch 21/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.6548 - accuracy: 0.7653 - val_loss: 0.6585 - val_accuracy: 0.7697\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.6720 - accuracy: 0.7620\n",
            "The parameters of CNN Model are:  {'normalcnnlayerfilter': 128, 'reductioncnnlayer1filter': 128, 'reductioncnnlayer2filter': 128, 'normallayerkernel': 2, 'reductionlayerkernel': 2, 'nrmllyractfn': 'gelu', 'rdclyractfn': 'sigmoid', 'optmzr': 'adam', 'epochs': 21}\n",
            "The accuracy of CNN Model is:  0.762\n",
            "Epoch 1/16\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 2.1275 - accuracy: 0.1882 - val_loss: 1.8804 - val_accuracy: 0.2300\n",
            "Epoch 2/16\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 1.7985 - accuracy: 0.2710 - val_loss: 1.7427 - val_accuracy: 0.3158\n",
            "Epoch 3/16\n",
            "500/500 [==============================] - 11s 23ms/step - loss: 1.6905 - accuracy: 0.3215 - val_loss: 1.6430 - val_accuracy: 0.3560\n",
            "Epoch 4/16\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 1.6064 - accuracy: 0.3711 - val_loss: 1.5726 - val_accuracy: 0.3918\n",
            "Epoch 5/16\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 1.5275 - accuracy: 0.4188 - val_loss: 1.4780 - val_accuracy: 0.4290\n",
            "Epoch 6/16\n",
            "500/500 [==============================] - 11s 23ms/step - loss: 1.4303 - accuracy: 0.4464 - val_loss: 1.3950 - val_accuracy: 0.4474\n",
            "Epoch 7/16\n",
            "500/500 [==============================] - 11s 23ms/step - loss: 1.3487 - accuracy: 0.4759 - val_loss: 1.3117 - val_accuracy: 0.4823\n",
            "Epoch 8/16\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 1.2880 - accuracy: 0.5020 - val_loss: 1.2620 - val_accuracy: 0.5218\n",
            "Epoch 9/16\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 1.2397 - accuracy: 0.5288 - val_loss: 1.2297 - val_accuracy: 0.5373\n",
            "Epoch 10/16\n",
            "500/500 [==============================] - 11s 23ms/step - loss: 1.1982 - accuracy: 0.5477 - val_loss: 1.2071 - val_accuracy: 0.5223\n",
            "Epoch 11/16\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 1.1634 - accuracy: 0.5600 - val_loss: 1.1505 - val_accuracy: 0.5775\n",
            "Epoch 12/16\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 1.1316 - accuracy: 0.5772 - val_loss: 1.1215 - val_accuracy: 0.5775\n",
            "Epoch 13/16\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 1.1051 - accuracy: 0.5849 - val_loss: 1.1034 - val_accuracy: 0.6005\n",
            "Epoch 14/16\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 1.0791 - accuracy: 0.5948 - val_loss: 1.0737 - val_accuracy: 0.5985\n",
            "Epoch 15/16\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 1.0579 - accuracy: 0.6032 - val_loss: 1.0595 - val_accuracy: 0.6046\n",
            "Epoch 16/16\n",
            "500/500 [==============================] - 11s 23ms/step - loss: 1.0388 - accuracy: 0.6092 - val_loss: 1.0356 - val_accuracy: 0.6170\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.0393 - accuracy: 0.6166\n",
            "The parameters of CNN Model are:  {'normalcnnlayerfilter': 128, 'reductioncnnlayer1filter': 16, 'reductioncnnlayer2filter': 16, 'normallayerkernel': 4, 'reductionlayerkernel': 1, 'nrmllyractfn': 'gelu', 'rdclyractfn': 'sigmoid', 'optmzr': 'adam', 'epochs': 16}\n",
            "The accuracy of CNN Model is:  0.617\n",
            "Epoch 1/20\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 1.6965 - accuracy: 0.3698 - val_loss: 1.2182 - val_accuracy: 0.5775\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 1.0630 - accuracy: 0.6197 - val_loss: 0.9570 - val_accuracy: 0.6605\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.9175 - accuracy: 0.6680 - val_loss: 0.8707 - val_accuracy: 0.6888\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.8394 - accuracy: 0.6978 - val_loss: 0.8387 - val_accuracy: 0.6888\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.7828 - accuracy: 0.7187 - val_loss: 0.7499 - val_accuracy: 0.7303\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.7378 - accuracy: 0.7371 - val_loss: 0.7155 - val_accuracy: 0.7429\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.7009 - accuracy: 0.7504 - val_loss: 0.6855 - val_accuracy: 0.7572\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.6676 - accuracy: 0.7614 - val_loss: 0.6686 - val_accuracy: 0.7621\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.6435 - accuracy: 0.7689 - val_loss: 0.6446 - val_accuracy: 0.7696\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.6204 - accuracy: 0.7758 - val_loss: 0.6082 - val_accuracy: 0.7806\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5998 - accuracy: 0.7834 - val_loss: 0.6007 - val_accuracy: 0.7845\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5821 - accuracy: 0.7902 - val_loss: 0.5713 - val_accuracy: 0.7942\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5649 - accuracy: 0.7967 - val_loss: 0.5676 - val_accuracy: 0.7997\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5523 - accuracy: 0.8024 - val_loss: 0.5400 - val_accuracy: 0.8051\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5369 - accuracy: 0.8053 - val_loss: 0.5529 - val_accuracy: 0.7976\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5269 - accuracy: 0.8101 - val_loss: 0.5297 - val_accuracy: 0.8077\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5150 - accuracy: 0.8146 - val_loss: 0.5131 - val_accuracy: 0.8157\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5105 - accuracy: 0.8151 - val_loss: 0.5067 - val_accuracy: 0.8148\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.5003 - accuracy: 0.8192 - val_loss: 0.4905 - val_accuracy: 0.8230\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.4921 - accuracy: 0.8215 - val_loss: 0.4923 - val_accuracy: 0.8245\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5228 - accuracy: 0.8129\n",
            "The parameters of CNN Model are:  {'normalcnnlayerfilter': 256, 'reductioncnnlayer1filter': 32, 'reductioncnnlayer2filter': 32, 'normallayerkernel': 1, 'reductionlayerkernel': 2, 'nrmllyractfn': 'swish', 'rdclyractfn': 'swish', 'optmzr': 'adam', 'epochs': 20}\n",
            "The accuracy of CNN Model is:  0.813\n",
            "Currently Runnung Generation is: 2\n",
            "Epoch 1/22\n",
            "500/500 [==============================] - 9s 16ms/step - loss: 1.6129 - accuracy: 0.4010 - val_loss: 1.1635 - val_accuracy: 0.5698\n",
            "Epoch 2/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 1.0291 - accuracy: 0.6335 - val_loss: 0.9576 - val_accuracy: 0.6515\n",
            "Epoch 3/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.9042 - accuracy: 0.6749 - val_loss: 0.8691 - val_accuracy: 0.6823\n",
            "Epoch 4/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.8361 - accuracy: 0.6978 - val_loss: 0.8002 - val_accuracy: 0.7103\n",
            "Epoch 5/22\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.7787 - accuracy: 0.7199 - val_loss: 0.7665 - val_accuracy: 0.7246\n",
            "Epoch 6/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.7349 - accuracy: 0.7330 - val_loss: 0.7100 - val_accuracy: 0.7385\n",
            "Epoch 7/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.6916 - accuracy: 0.7497 - val_loss: 0.6749 - val_accuracy: 0.7552\n",
            "Epoch 8/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.6558 - accuracy: 0.7640 - val_loss: 0.6446 - val_accuracy: 0.7655\n",
            "Epoch 9/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.6310 - accuracy: 0.7721 - val_loss: 0.6141 - val_accuracy: 0.7762\n",
            "Epoch 10/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.6049 - accuracy: 0.7833 - val_loss: 0.5967 - val_accuracy: 0.7865\n",
            "Epoch 11/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5858 - accuracy: 0.7891 - val_loss: 0.6078 - val_accuracy: 0.7818\n",
            "Epoch 12/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5656 - accuracy: 0.7952 - val_loss: 0.5641 - val_accuracy: 0.7964\n",
            "Epoch 13/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5492 - accuracy: 0.8009 - val_loss: 0.5485 - val_accuracy: 0.8031\n",
            "Epoch 14/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5330 - accuracy: 0.8084 - val_loss: 0.5332 - val_accuracy: 0.8078\n",
            "Epoch 15/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5214 - accuracy: 0.8113 - val_loss: 0.5389 - val_accuracy: 0.8062\n",
            "Epoch 16/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5097 - accuracy: 0.8153 - val_loss: 0.5193 - val_accuracy: 0.8128\n",
            "Epoch 17/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.4987 - accuracy: 0.8191 - val_loss: 0.5099 - val_accuracy: 0.8173\n",
            "Epoch 18/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.4936 - accuracy: 0.8195 - val_loss: 0.5075 - val_accuracy: 0.8114\n",
            "Epoch 19/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.4839 - accuracy: 0.8244 - val_loss: 0.5237 - val_accuracy: 0.8073\n",
            "Epoch 20/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.4751 - accuracy: 0.8274 - val_loss: 0.4802 - val_accuracy: 0.8252\n",
            "Epoch 21/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.4653 - accuracy: 0.8319 - val_loss: 0.4840 - val_accuracy: 0.8244\n",
            "Epoch 22/22\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.4597 - accuracy: 0.8332 - val_loss: 0.4961 - val_accuracy: 0.8158\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5163 - accuracy: 0.8101\n",
            "The parameters of CNN Model are:  {'normalcnnlayerfilter': 64, 'reductioncnnlayer1filter': 64, 'reductioncnnlayer2filter': 64, 'normallayerkernel': 7, 'reductionlayerkernel': 6, 'nrmllyractfn': 'swish', 'rdclyractfn': 'relu', 'optmzr': 'adam', 'epochs': 22}\n",
            "The accuracy of CNN Model is:  0.81\n",
            "Epoch 1/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 1.9497 - accuracy: 0.2518 - val_loss: 1.7202 - val_accuracy: 0.3555\n",
            "Epoch 2/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 1.5540 - accuracy: 0.4247 - val_loss: 1.3589 - val_accuracy: 0.4878\n",
            "Epoch 3/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 1.2603 - accuracy: 0.5336 - val_loss: 1.2003 - val_accuracy: 0.5733\n",
            "Epoch 4/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 1.1311 - accuracy: 0.5848 - val_loss: 1.0804 - val_accuracy: 0.6119\n",
            "Epoch 5/21\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 1.0408 - accuracy: 0.6136 - val_loss: 1.0021 - val_accuracy: 0.6353\n",
            "Epoch 6/21\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.9751 - accuracy: 0.6372 - val_loss: 0.9549 - val_accuracy: 0.6488\n",
            "Epoch 7/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.9305 - accuracy: 0.6543 - val_loss: 0.9290 - val_accuracy: 0.6647\n",
            "Epoch 8/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.8919 - accuracy: 0.6709 - val_loss: 0.8848 - val_accuracy: 0.6729\n",
            "Epoch 9/21\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.8602 - accuracy: 0.6849 - val_loss: 0.8567 - val_accuracy: 0.6870\n",
            "Epoch 10/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.8357 - accuracy: 0.6952 - val_loss: 0.8401 - val_accuracy: 0.7028\n",
            "Epoch 11/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.8090 - accuracy: 0.7062 - val_loss: 0.8235 - val_accuracy: 0.6994\n",
            "Epoch 12/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.7870 - accuracy: 0.7156 - val_loss: 0.7718 - val_accuracy: 0.7267\n",
            "Epoch 13/21\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.7669 - accuracy: 0.7206 - val_loss: 0.7614 - val_accuracy: 0.7320\n",
            "Epoch 14/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.7485 - accuracy: 0.7309 - val_loss: 0.7333 - val_accuracy: 0.7418\n",
            "Epoch 15/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.7285 - accuracy: 0.7375 - val_loss: 0.7218 - val_accuracy: 0.7412\n",
            "Epoch 16/21\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.7095 - accuracy: 0.7454 - val_loss: 0.7070 - val_accuracy: 0.7498\n",
            "Epoch 17/21\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.6947 - accuracy: 0.7516 - val_loss: 0.6853 - val_accuracy: 0.7654\n",
            "Epoch 18/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.6778 - accuracy: 0.7572 - val_loss: 0.6834 - val_accuracy: 0.7648\n",
            "Epoch 19/21\n",
            "500/500 [==============================] - 16s 33ms/step - loss: 0.6611 - accuracy: 0.7621 - val_loss: 0.6495 - val_accuracy: 0.7726\n",
            "Epoch 20/21\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.6477 - accuracy: 0.7689 - val_loss: 0.6495 - val_accuracy: 0.7656\n",
            "Epoch 21/21\n",
            "500/500 [==============================] - 17s 33ms/step - loss: 0.6351 - accuracy: 0.7741 - val_loss: 0.6348 - val_accuracy: 0.7734\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6504 - accuracy: 0.7666\n",
            "The parameters of CNN Model are:  {'normalcnnlayerfilter': 128, 'reductioncnnlayer1filter': 128, 'reductioncnnlayer2filter': 128, 'normallayerkernel': 2, 'reductionlayerkernel': 2, 'nrmllyractfn': 'gelu', 'rdclyractfn': 'sigmoid', 'optmzr': 'adam', 'epochs': 21}\n",
            "The accuracy of CNN Model is:  0.767\n",
            "Epoch 1/31\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 1.8076 - accuracy: 0.3136 - val_loss: 1.4488 - val_accuracy: 0.4825\n",
            "Epoch 2/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 1.2056 - accuracy: 0.5588 - val_loss: 1.0719 - val_accuracy: 0.6069\n",
            "Epoch 3/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.9566 - accuracy: 0.6550 - val_loss: 0.8732 - val_accuracy: 0.6904\n",
            "Epoch 4/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.8446 - accuracy: 0.6930 - val_loss: 0.7938 - val_accuracy: 0.7141\n",
            "Epoch 5/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.7873 - accuracy: 0.7117 - val_loss: 0.7748 - val_accuracy: 0.7193\n",
            "Epoch 6/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.7459 - accuracy: 0.7273 - val_loss: 0.7536 - val_accuracy: 0.7235\n",
            "Epoch 7/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.7081 - accuracy: 0.7417 - val_loss: 0.6772 - val_accuracy: 0.7559\n",
            "Epoch 8/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.6707 - accuracy: 0.7553 - val_loss: 0.6534 - val_accuracy: 0.7627\n",
            "Epoch 9/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.6389 - accuracy: 0.7659 - val_loss: 0.6335 - val_accuracy: 0.7682\n",
            "Epoch 10/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.6132 - accuracy: 0.7745 - val_loss: 0.6027 - val_accuracy: 0.7832\n",
            "Epoch 11/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5910 - accuracy: 0.7833 - val_loss: 0.5876 - val_accuracy: 0.7862\n",
            "Epoch 12/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5762 - accuracy: 0.7894 - val_loss: 0.5626 - val_accuracy: 0.7983\n",
            "Epoch 13/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5578 - accuracy: 0.7969 - val_loss: 0.5601 - val_accuracy: 0.7993\n",
            "Epoch 14/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.5448 - accuracy: 0.8024 - val_loss: 0.5379 - val_accuracy: 0.8086\n",
            "Epoch 15/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.5310 - accuracy: 0.8073 - val_loss: 0.5277 - val_accuracy: 0.8104\n",
            "Epoch 16/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.5204 - accuracy: 0.8133 - val_loss: 0.5233 - val_accuracy: 0.8077\n",
            "Epoch 17/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.5089 - accuracy: 0.8160 - val_loss: 0.5023 - val_accuracy: 0.8190\n",
            "Epoch 18/31\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.5001 - accuracy: 0.8201 - val_loss: 0.5292 - val_accuracy: 0.8076\n",
            "Epoch 19/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.4880 - accuracy: 0.8237 - val_loss: 0.5045 - val_accuracy: 0.8234\n",
            "Epoch 20/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.4807 - accuracy: 0.8265 - val_loss: 0.4880 - val_accuracy: 0.8264\n",
            "Epoch 21/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.4712 - accuracy: 0.8296 - val_loss: 0.4771 - val_accuracy: 0.8266\n",
            "Epoch 22/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.4669 - accuracy: 0.8301 - val_loss: 0.4907 - val_accuracy: 0.8238\n",
            "Epoch 23/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.4588 - accuracy: 0.8345 - val_loss: 0.4716 - val_accuracy: 0.8285\n",
            "Epoch 24/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.4523 - accuracy: 0.8357 - val_loss: 0.4603 - val_accuracy: 0.8297\n",
            "Epoch 25/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.4447 - accuracy: 0.8407 - val_loss: 0.4600 - val_accuracy: 0.8324\n",
            "Epoch 26/31\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.4378 - accuracy: 0.8423 - val_loss: 0.4482 - val_accuracy: 0.8383\n",
            "Epoch 27/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.4351 - accuracy: 0.8425 - val_loss: 0.4394 - val_accuracy: 0.8424\n",
            "Epoch 28/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.4301 - accuracy: 0.8468 - val_loss: 0.4486 - val_accuracy: 0.8378\n",
            "Epoch 29/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.4217 - accuracy: 0.8490 - val_loss: 0.4326 - val_accuracy: 0.8470\n",
            "Epoch 30/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.4185 - accuracy: 0.8506 - val_loss: 0.4282 - val_accuracy: 0.8445\n",
            "Epoch 31/31\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.4163 - accuracy: 0.8506 - val_loss: 0.4327 - val_accuracy: 0.8409\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4471 - accuracy: 0.8434\n",
            "The parameters of CNN Model are:  {'normalcnnlayerfilter': 256, 'reductioncnnlayer1filter': 32, 'reductioncnnlayer2filter': 32, 'normallayerkernel': 1, 'reductionlayerkernel': 2, 'nrmllyractfn': 'swish', 'rdclyractfn': 'swish', 'optmzr': 'adam', 'epochs': 31}\n",
            "The accuracy of CNN Model is:  0.843\n",
            "Epoch 1/26\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 1.5879 - accuracy: 0.4176 - val_loss: 1.1341 - val_accuracy: 0.6022\n",
            "Epoch 2/26\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 1.0413 - accuracy: 0.6208 - val_loss: 0.9997 - val_accuracy: 0.6309\n",
            "Epoch 3/26\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.9207 - accuracy: 0.6639 - val_loss: 0.8709 - val_accuracy: 0.6842\n",
            "Epoch 4/26\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.8477 - accuracy: 0.6886 - val_loss: 0.8176 - val_accuracy: 0.6984\n",
            "Epoch 5/26\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.7928 - accuracy: 0.7109 - val_loss: 0.7599 - val_accuracy: 0.7220\n",
            "Epoch 6/26\n",
            "113/500 [=====>........................] - ETA: 12s - loss: 0.7553 - accuracy: 0.7258"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skMI2ibqI-Wr"
      },
      "source": [
        "arr=[]\n",
        "for value in track_of_param_and_accuracy.get(highest_acc_with_param).values():\n",
        "    arr.append(value)\n",
        "\n",
        "print(\"NC\",arr[0],arr[3],arr[5]+\";\"+\"RC\",arr[1],arr[4],arr[6]+\";\"+\"RC\",arr[1],arr[4],arr[6]+\";\"+\"FL\",\"sigmoid\"+\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do9UhsVQKrHc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}